{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract subset of columns from STATA/SAS files\n",
    "Return a subcopy of data sets 2007-2014 containing only the following columns:\n",
    "\n",
    "- lpnr \n",
    "- kon \n",
    "- atc \n",
    "- edatum\n",
    "\n",
    "Output is written as a CSV file, since I couldn't figure out a quick and clean way of writing a STAT/SAS file without loading the entire data set into memory at once (which I cannot do on my laptop unfortunately :)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Required imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lmed2007.sas7bdat contains 89065305 rows\n"
     ]
    }
   ],
   "source": [
    "# Trying with SAS format files instead:\n",
    "def extract_columns_from_sas(filename, columns, output_csv, chunksize=100000):\n",
    "    \"\"\"Iterate through SAS file in chunks,\n",
    "    extract headers from chunks into separate subdataframe,\n",
    "    convert contents to string (instead of bytestring)\n",
    "    write (append) extracted headers from chunk to CSV file,\n",
    "    then write resulting dataframe to disk.\n",
    "    Pray not to run out of memory...\n",
    "    \"\"\"\n",
    "\n",
    "    reader = pd.read_sas(filename, chunksize=chunksize, encoding='latin1')\n",
    "    print(filename, \"contains\", reader.row_count, \"rows\")\n",
    "\n",
    "    for count, chunk in enumerate(reader, start=1):\n",
    "        percent_read = count*chunksize / reader.row_count\n",
    "        if int(percent_read) % 10:\n",
    "            print(\"{:3.4f} % read\".format(percent_read))\n",
    "        if count == 1:\n",
    "            chunk.to_csv(output_csv, columns=columns, index=False, mode='a')\n",
    "        else:\n",
    "            chunk.to_csv(output_csv, columns=columns, index=False, mode='a', header=False)\n",
    "\n",
    "lmed_files = [\"lmed2007.sas7bdat\", \n",
    "              \"lmed2008.sas7bdat\",\n",
    "              \"lmed2009.sas7bdat\",\n",
    "              \"lmed2010.sas7bdat\",\n",
    "              \"lmed2011.sas7bdat\",\n",
    "              \"lmed2012.sas7bdat\",\n",
    "              \"lmed2013.sas7bdat\",\n",
    "              \"lmed2014.sas7bdat\",\n",
    "            ]\n",
    "\n",
    "for lmed_file in lmed_files:\n",
    "    extract_columns_from_sas(lmed_file, columns=[\"lpnr\", \"KON\", \"atc\", \"EDATUM\"], output_csv=lmed_file+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Version of given Stata file is not 104, 105, 108, 111 (Stata 7SE), 113 (Stata 8/9), 114 (Stata 10/11), 115 (Stata 12), 117 (Stata 13), or 118 (Stata 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a83eeb057044>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Trying to open STATA format (dta) gives a file version error:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mitr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_stata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"lmed2007.dta\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\fredbo\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\stata.py\u001b[0m in \u001b[0;36mread_stata\u001b[1;34m(filepath_or_buffer, convert_dates, convert_categoricals, encoding, index, convert_missing, preserve_dtypes, columns, order_categoricals, chunksize, iterator)\u001b[0m\n\u001b[0;32m    165\u001b[0m                          \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m                          \u001b[0morder_categoricals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder_categoricals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m                          chunksize=chunksize, encoding=encoding)\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0miterator\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\fredbo\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\stata.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_buf, convert_dates, convert_categoricals, index, convert_missing, preserve_dtypes, columns, order_categoricals, encoding, chunksize)\u001b[0m\n\u001b[0;32m    976\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath_or_buf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 978\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_header\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    979\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\fredbo\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\stata.py\u001b[0m in \u001b[0;36m_read_header\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    998\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_new_header\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_char\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1000\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_old_header\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_char\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1001\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1002\u001b[0m         self.has_string_data = len([x for x in self.typlist\n",
      "\u001b[1;32mC:\\Users\\fredbo\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\stata.py\u001b[0m in \u001b[0;36m_read_old_header\u001b[1;34m(self, first_char)\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_version\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst_char\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_version\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m104\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m105\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m108\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m111\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m113\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m114\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m115\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1203\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_version_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1204\u001b[0m         self.byteorder = struct.unpack('b', self.path_or_buf.read(1))[\n\u001b[0;32m   1205\u001b[0m             0] == 0x1 and '>' or '<'\n",
      "\u001b[1;31mValueError\u001b[0m: Version of given Stata file is not 104, 105, 108, 111 (Stata 7SE), 113 (Stata 8/9), 114 (Stata 10/11), 115 (Stata 12), 117 (Stata 13), or 118 (Stata 14)"
     ]
    }
   ],
   "source": [
    "# Trying to open STATA format (dta) gives a file version error:\n",
    "itr = pd.read_stata(\"lmed2007.dta\", chunksize=10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
